<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Spencer Braun</title>
    <link>https://spencerbraun.github.io/</link>
    <description>Recent content on Spencer Braun</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 22 Jul 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://spencerbraun.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>About</title>
      <link>https://spencerbraun.github.io/about/</link>
      <pubDate>Fri, 22 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://spencerbraun.github.io/about/</guid>
      <description>I&amp;rsquo;m a research scientist focused on natural language processing and multimodal applications of transformers. I currently work at Primer, a startup focused on bringing NLP-enhanced tools to intelligence and defense applications. My research interests are broad, but lately I am especially excited by information embedding and retrieval, relation extraction and growing knowledge bases, and data efficient methods.
My prior experiences are diverse, and I&amp;rsquo;m lucky to have collaborated with many talented economists, statisticians, computer scientists, and physicists.</description>
    </item>
    
    <item>
      <title>NAACL 2022: Does Summary Evaluation Survive Translation?</title>
      <link>https://spencerbraun.github.io/posts/does-summary-evaluation-survive-translation/</link>
      <pubDate>Fri, 22 Jul 2022 00:00:00 +0000</pubDate>
      
      <guid>https://spencerbraun.github.io/posts/does-summary-evaluation-survive-translation/</guid>
      <description>Paper
Code
I recently presented a paper at the NAACL 2022 conference for work conducted with my colleagues at Primer in collaboration with Technische Universität Berlin. At Primer, summarization is a core task that our platform performs daily, but summarization evaluation is quite challenging even in English. Since we are often presented with data from many languages, we explored whether summarization datasets could remain useful under translation, as resources for non-English languages are far less plentiful.</description>
    </item>
    
    <item>
      <title>Demand Forecasting with Bayesian Methods</title>
      <link>https://spencerbraun.github.io/posts/demand-forecasting-with-bayesian-methods/</link>
      <pubDate>Thu, 22 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://spencerbraun.github.io/posts/demand-forecasting-with-bayesian-methods/</guid>
      <description>The Stanford Medical system sees a constant stream of patients through its doors every year, many of whom require intensive care. Blood transfusions are a common occurrence as part of a therapy or surgery, but blood platelets are a scarce resource that have a short shelf life. Therefore accurately predicting future demand is essential in order to minimize waste while ensuring hospitals have enough on hand for the current patient population.</description>
    </item>
    
    <item>
      <title>Selectively Editable Language Models</title>
      <link>https://spencerbraun.github.io/posts/selectively-editable-language-models/</link>
      <pubDate>Wed, 14 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://spencerbraun.github.io/posts/selectively-editable-language-models/</guid>
      <description>The post belows explains a project in editing language models I completed as part of Stanford’s course in natural language processing. If you want to skip to the point, the report and code are freely available.
Background: Taming Large Language Models Large language models have been an area of exciting development in the last few years, and we now have applications and entire companies built around their improving performance and utility.</description>
    </item>
    
    <item>
      <title>Chinese Word Segmentation: Classic and Modern Methods</title>
      <link>https://spencerbraun.github.io/posts/chinese-segmentation-classic-and-modern-methods/</link>
      <pubDate>Sat, 10 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://spencerbraun.github.io/posts/chinese-segmentation-classic-and-modern-methods/</guid>
      <description>Part of the fun of NLP is the diversity of language structures that models must consider. Tools that are built in a monolingual context can easily fail to achieve more global utility. If you just work in English, you may find word embeddings fun and useful, but the German Komposita don’t fit neatly into our English-centric boxes. Similarly, once we leave the Latin alphabet, we acquire all sorts of new challenges.</description>
    </item>
    
    <item>
      <title>Unsupervised Text Style Transfer with Deep Learning</title>
      <link>https://spencerbraun.github.io/posts/generative_text_style_transfer/</link>
      <pubDate>Mon, 08 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://spencerbraun.github.io/posts/generative_text_style_transfer/</guid>
      <description>Natural Language Processing (NLP) is one area of deep learning that continues to make substantial, and often surprising, progress while also adding value to existing businesses. Supervised tasks like neural machine translation produce high quality, real-time results and Gmail&amp;rsquo;s predictive text feature often feels like magic. I have been most interested in recent applications of generative text models, such as using GPT-2 to play chess, write poetry, or create custom games.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://spencerbraun.github.io/archives/</link>
      <pubDate>Tue, 28 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://spencerbraun.github.io/archives/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
